import os
import json
import google.generativeai as genai
from typing import Dict, Any, Optional
import re

# Importa√ß√£o condicional da OpenAI
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  OpenAI n√£o dispon√≠vel. Usando apenas Google Gemini.")
    OPENAI_AVAILABLE = False

class AIAnalyzer:
    def __init__(self):
        # ‚úÖ CARREGAR .env PRIMEIRO
        from dotenv import load_dotenv
        load_dotenv()
        
        # Configura√ß√£o do Gemini (PRIORIDADE AGORA)
        gemini_key = os.getenv('GOOGLE_API_KEY')
        
        if gemini_key:
            try:
                genai.configure(api_key=gemini_key)
                self.gemini_client = genai
                self.gemini_available = True
                
                # Modelos de texto - vers√µes CORRETAS
                text_models_priority = [
                    'gemini-2.0-flash',           # Modelo r√°pido e eficiente
                    'gemini-2.0-flash-001',       # Vers√£o espec√≠fica
                    'gemini-pro-latest',          # Modelo est√°vel
                ]
                
                # Tentar usar um modelo de texto
                self.gemini_model = None
                for model_name in text_models_priority:
                    try:
                        model = genai.GenerativeModel(model_name)
                        # Teste simples
                        test_response = model.generate_content("Test")
                        self.gemini_model = model_name
                        print(f"‚úÖ Modelo Gemini selecionado: {self.gemini_model}")
                        break
                    except Exception as e:
                        print(f"‚ùå Modelo {model_name} n√£o dispon√≠vel: {e}")
                        continue
                
                # Se nenhum modelo funcionou
                if not self.gemini_model:
                    self.gemini_available = False
                    print("‚ùå Nenhum modelo Gemini funcionou")
                
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao configurar Gemini: {e}")
                self.gemini_available = False
        else:
            self.gemini_available = False
            print("‚ùå GOOGLE_API_KEY n√£o encontrada")
        
        # Configura√ß√£o do OpenAI (APENAS SE DISPON√çVEL)
        self.openai_available = False
        if OPENAI_AVAILABLE and os.getenv('OPENAI_API_KEY'):
            try:
                openai_key = os.getenv('OPENAI_API_KEY')
                self.openai_client = OpenAI(api_key=openai_key)
                self.openai_available = True
                print("‚úÖ OpenAI configurado")
            except Exception as e:
                print(f"‚ö†Ô∏è  OpenAI n√£o configurado: {e}")
                self.openai_available = False
        
        # Provider padr√£o - PRIORIDADE GEMINI
        if self.gemini_available:
            self.current_provider = 'gemini'
            print(f"üöÄ Google Gemini configurado como provider principal")
        elif self.openai_available:
            self.current_provider = 'openai'
            print("ü§ñ OpenAI como provider")
        else:
            self.current_provider = None
            print("‚ùå Nenhuma API de IA dispon√≠vel!")

    def analyze_candidate(self, candidate_data, job_requirements):
        """
        Analisa um candidato usando Gemini PRIMEIRO
        """
        prompt = self._build_analysis_prompt(candidate_data, job_requirements)
        
        # Tentar Gemini PRIMEIRO
        if self.gemini_available:
            try:
                analysis = self._analyze_with_gemini(prompt)
                self.current_provider = 'gemini'
                print(f"ü§ñ An√°lise realizada com Google Gemini ({self.gemini_model})")
                return analysis
            except Exception as e:
                print(f"‚ùå Gemini falhou: {e}")
        
        # Fallback para OpenAI
        if self.openai_available:
            try:
                analysis = self._analyze_with_openai(prompt)
                self.current_provider = 'openai'
                print("ü§ñ An√°lise realizada com OpenAI")
                return analysis
            except Exception as e:
                print(f"‚ùå OpenAI tamb√©m falhou: {e}")
        
        # Se ambas falharem
        print("‚ùå Todas as APIs falharam. Retornando an√°lise padr√£o.")
        return self._get_fallback_analysis()

    def _build_analysis_prompt(self, candidate_data, job_requirements):
        """Constr√≥i o prompt para an√°lise com crit√©rios rigorosos de senioridade"""
        
        json_template = '''{
    "contact_info": {
        "email": "email@exemplo.com ou null",
        "phone": "+55 11 99999-9999 ou null",
        "linkedin": "https://linkedin.com/in/usuario ou null"
    },
    "extracted_skills": ["skill1","skill2","skill3"],
    "seniority_detected": "J√∫nior" | "Pleno" | "S√™nior" | "Especialista" | "Coordenador" | "Gerente" | "Diretor",
    "experience_years": 4.5,
    "experience_summary": "Resumo de experi√™ncias relevantes em 2-3 linhas",
    "leadership_responsibilities": ["exemplo: liderou time de 5 pessoas","exemplo: gerenciou budget X"],
    "complexity_indicators": ["arquitetura distribu√≠da","integra√ß√£o multi-sistemas"],
    "mentorship_indicators": ["mentoria interna","treinamentos conduzidos"],
    "strengths": "Principais pontos fortes em 2-3 linhas",
    "weaknesses": "Poss√≠veis pontos fracos em 2-3 linhas",
    "hard_skills_score": 8.5,
    "soft_skills_score": 7.0,
    "overall_score": 7.8,
    "professional_summary": "Resumo profissional em at√© 3 linhas",
    "recommendation": "Altamente Recomendado" | "Recomendado" | "Parcialmente Recomendado" | "N√£o Recomendado",
    "potential_risks": "Poss√≠veis riscos na contrata√ß√£o em 1-2 linhas"
}'''
        
        prompt = f"""
AN√ÅLISE DE CANDIDATO - ESPECIALISTA EM RECRUTAMENTO

Objetivo: extrair informa√ß√µes do candidato e classificar senioridade com regras r√≠gidas.

**VAGA:**
- Cargo: {job_requirements.get('title', 'N√£o especificado')}
- N√≠vel: {job_requirements.get('level', 'N√£o especificado')}
- Descri√ß√£o: {job_requirements.get('description', 'N√£o especificado')}
- Skills Requeridas: {job_requirements.get('requirements', 'N√£o especificado')}

**CANDIDATO:**
Nome: {candidate_data.get('name', 'N√£o informado')}
Curr√≠culo/Perfil: {candidate_data.get('resume_text', 'N√£o informado')}

Retorne APENAS o JSON v√°lido conforme template abaixo:

{json_template}
"""
        return prompt

    def _analyze_with_gemini(self, prompt):
        """An√°lise usando Google Gemini"""
        if not self.gemini_available:
            raise Exception("Gemini n√£o dispon√≠vel")
        
        try:
            model = genai.GenerativeModel(self.gemini_model)
            
            generation_config = {
                "temperature": 0.1,
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 2000,
            }
            
            gemini_prompt = f"""
{prompt}

IMPORTANTE: Retorne APENAS o JSON v√°lido, sem nenhum texto adicional.
"""
            
            response = model.generate_content(
                gemini_prompt,
                generation_config=generation_config
            )
            
            if not response.parts:
                raise Exception("Resposta vazia do Gemini")
            
            return self._parse_ai_response(response.text)
            
        except Exception as e:
            print(f"‚ùå Erro com Gemini: {e}")
            raise e

    def _analyze_with_openai(self, prompt):
        """An√°lise usando OpenAI"""
        if not self.openai_available:
            raise Exception("OpenAI n√£o dispon√≠vel")
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em an√°lise de candidatos. Retorne apenas JSON v√°lido."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1500
            )
            
            content = response.choices[0].message.content.strip()
            return self._parse_ai_response(content)
        except Exception as e:
            print(f"‚ùå Erro com OpenAI: {e}")
            raise e

    def _parse_ai_response(self, content):
        """Parseia a resposta da AI - M√âTODO QUE ESTAVA FALTANDO"""
        # Remove markdown se presente
        if content.startswith("```json"):
            content = content.replace("```json", "").replace("```", "").strip()
        elif content.startswith("```"):
            content = content.replace("```", "").strip()
        
        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            print(f"‚ùå Erro ao fazer parse do JSON: {e}")
            # Tentar extrair JSON do texto
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                try:
                    return json.loads(json_match.group())
                except:
                    pass
            raise e

    def _get_fallback_analysis(self):
        """Retorna an√°lise padr√£o em caso de erro - M√âTODO QUE ESTAVA FALTANDO"""
        return {
            "contact_info": {
                "email": None,
                "phone": None,
                "linkedin": None
            },
            "extracted_skills": ["An√°lise manual necess√°ria"],
            "seniority_detected": "N√£o detectado",
            "experience_years": 0,
            "experience_summary": "Erro ao processar. An√°lise manual recomendada.",
            "leadership_responsibilities": [],
            "complexity_indicators": [],
            "mentorship_indicators": [],
            "strengths": "Pendente de an√°lise manual",
            "weaknesses": "Pendente de an√°lise manual",
            "hard_skills_score": 5.0,
            "soft_skills_score": 5.0,
            "overall_score": 5.0,
            "professional_summary": "Erro na an√°lise autom√°tica. Revis√£o manual necess√°ria.",
            "recommendation": "An√°lise Manual Necess√°ria",
            "potential_risks": "An√°lise autom√°tica falhou"
        }

    def get_current_provider(self):
        """Retorna qual provider est√° sendo usado atualmente"""
        return self.current_provider

    def is_any_ai_available(self):
        """Verifica se alguma API est√° dispon√≠vel"""
        return self.gemini_available or self.openai_available